{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NERD","text":"<p>NERD (Nucleic acid Energetics from Reactivity Data) is a unified toolkit for extracting nucleotide-level thermodynamic and kinetic information from chemical probing experiments. It streamlines sample registration, mutation-count processing, and kinetic/melt-fit analysis, providing an organized path from raw sequencing data to time-course and temperature-gradient energetics.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># create a virtual environment (recommended)\npython -m venv .venv\nsource .venv/bin/activate\n\n# install NERD\npip install nerd-pipeline\n\n# initialize a project from an example config\nnerd run create demo_folder/01_create_samples/configs/create_meta.yaml\n\n# execute a probe timecourse fit\nnerd run probe_timecourse demo_folder/05_probe_tc_kinetics/configs/probe_tc.yaml\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Unified SQLite backbone linking constructs, buffers, reactions, fits, and artifacts</li> <li>CLI-based execution with consistent logging, caching, and reproducibility guarantees</li> <li>Pluggable fitting engines for probe timecourses, Arrhenius, and two-state melt models</li> <li>Rich filtering (construct, buffer, probe, nt_id, base) and outlier management in configs</li> <li>Automated metadata ingestion from CSVs and lab notebooks</li> <li>Portable outputs (JSON artifacts, logs, database entries) for downstream visualization</li> <li>Local and remote execution modes (local CPU, SLURM, SSH)</li> <li>Tutorial notebooks and guides for sample organization, NMR kinetics, probe analyses, and tempgrad fits</li> </ul>"},{"location":"#documentation-map","title":"Documentation Map","text":"<ul> <li>Getting Started: Sample organization &amp; database layout</li> <li>Guides:</li> <li>Probe timecourse workflow</li> <li>NMR kinetics workflow</li> <li>Temperature-gradient fitting</li> <li>CLI Reference: <code>nerd run \u2026</code></li> <li>create</li> <li>mut_count</li> <li>nmr_create</li> <li>nmr_deg_kinetics</li> <li>nmr_add_kinetics</li> <li>probe_timecourse</li> <li>tempgrad_fit</li> <li>Configuration &amp; Workflow Guide: See guides above plus example YAML in <code>demo_folder/</code></li> <li>Architecture Overview: Sample organization &amp; database layout</li> <li>Examples: Explore <code>demo_folder/</code> configs, <code>examples/nerd.sqlite</code>, and accompanying notebooks</li> </ul>"},{"location":"#how-it-works","title":"How It Works","text":"<p>[Pipeline diagram here: sample CSVs &amp; raw data \u2192 NERD CLI tasks \u2192 SQLite database \u2192 fit engines \u2192 JSON/plots]</p> <ol> <li>Register constructs, buffers, reaction groups, and traces with <code>nerd run create</code>.</li> <li>Quantify sequencing or NMR data via task-specific runners (<code>mut_count</code>, <code>nmr_*</code>).</li> <li>Execute probe timecourse fits to derive kinetic parameters per nucleotide.</li> <li>Run <code>tempgrad_fit</code> to combine kinetics across temperatures with Arrhenius or two-state models.</li> <li>Visualize results using bundled notebooks or your own data science stack.</li> </ol>"},{"location":"#example-output-optional","title":"Example Output (Optional)","text":"<pre><code>manuscript_pipeline/05_probe_tempgrad_fit/tempgrad_fit/latest/results/tempgrad_result.json\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<p>Please cite the NERD pipeline as: [placeholder\u2014add citation here].</p>"},{"location":"#links","title":"Links","text":"<ul> <li>GitHub Repository</li> <li>Issue Tracker</li> <li>License</li> </ul>"},{"location":"cli/create/","title":"<code>nerd create</code>","text":"<p><code>nerd create</code> ingests metadata (constructs, buffers, sequencing runs, samples) into a NERD SQLite database. It is typically the first task you run when setting up a new analysis.</p> <pre><code>nerd create --config PATH/TO/config.yaml --db PATH/TO/nerd.sqlite\n</code></pre> <p>If <code>--db</code> is omitted, the CLI creates/updates <code>nerd.sqlite</code> inside <code>run.output_dir</code>.</p>"},{"location":"cli/create/#configuration-layout","title":"Configuration Layout","text":"<p>Every config has two top-level sections:</p> <pre><code>run:\n  label: create_all_samples         # used in output paths\n  output_dir: examples              # base directory for logs &amp; artifacts\n  backend: local                    # optional: slurm / ssh\n\ncreate:\n  buffers: buffers.csv\n  constructs: constructs.csv\n  sequencing_runs: sequencing_runs.csv\n  samples: probing_samples.csv\n  derived_samples: derived.csv      # optional\n</code></pre> <ul> <li><code>run</code> block \u2013 standard NERD metadata (label, output directory, execution backend, resources).</li> <li><code>create</code> block \u2013 describes what to import. Values can be inline objects or CSV filenames relative to the config (or resolved via <code>search_roots</code>).</li> </ul>"},{"location":"cli/create/#csv-mode","title":"CSV Mode","text":"<p>When a value is a string (e.g., <code>samples: probing_samples.csv</code>), <code>nerd create</code> treats it as a sheet:</p> <ul> <li><code>buffers.csv</code> \u2192 inserted into <code>meta_buffers</code>.</li> <li><code>constructs.csv</code> \u2192 inserted into <code>meta_constructs</code> (optionally with <code>nt_info</code> paths).</li> <li><code>sequencing_runs.csv</code> \u2192 inserted into <code>sequencing_runs</code>.</li> <li><code>probing_samples.csv</code> \u2192 inserted into <code>sequencing_samples</code>, plus derived <code>probe_reactions</code>/<code>probe_reaction_groups</code>.</li> </ul> <p>Columns should match the spreadsheet headers (see <code>examples/create_all_samples/to_import/</code>). Extra columns are ignored; missing required columns raise errors.</p>"},{"location":"cli/create/#yaml-mode","title":"YAML Mode","text":"<p>You can inline dictionaries instead of CSV files:</p> <pre><code>create:\n  buffers:\n    - name: Schwalbe_bistris\n      pH: 6.5\n      composition: Tris/Bicine\n      disp_name: pH6.5_A\n  constructs:\n    - family: HIV\n      name: fourU_new\n      version: 2\n      sequence: ACTG...\n      disp_name: 4U_wt\n      nt_info: fourU_wt_nt.csv     # optional relative path\n</code></pre> <p>Inline mode is best for small test cases; CSV mode scales better for large studies.</p>"},{"location":"cli/create/#sample-ingestion-details","title":"Sample Ingestion Details","text":"<p>When loading samples from CSV:</p> <ul> <li><code>sequencing_run_name</code> is used to look up (or create) sequencing runs.</li> <li><code>construct</code> and <code>buffer</code> names are resolved against the database (using either <code>disp_name</code> or <code>name</code>). Missing references throw errors before any reactions are inserted.</li> <li><code>reaction_group</code> labels are turned into <code>probe_reaction_groups</code>, and each sample becomes a row in <code>probe_reactions</code> with the associated metadata (<code>temperature</code>, <code>reaction_time</code>, etc.).</li> </ul> <p>If you omit constructs or buffers in the sheet, you may supply defaults in the YAML; otherwise, <code>nerd create</code> requires every sample to specify a valid reference.</p>"},{"location":"cli/create/#trace-of-inserted-objects","title":"Trace of Inserted Objects","text":"<p>The task writes two log files in the run directory:</p> <ul> <li><code>created_objects.json</code></li> <li><code>created_objects.log</code></li> </ul> <p>Both summarize how many buffers, constructs, sequencing runs, and samples were created or updated. Use them to confirm the import before running downstream tasks.</p>"},{"location":"cli/create/#common-flags","title":"Common Flags","text":"Option Description <code>--config</code> Path to YAML file (required). <code>--db</code> SQLite database path; defaults to <code>&lt;run.output_dir&gt;/nerd.sqlite</code>. <code>--verbose</code> Enables DEBUG logging. <code>--log-file</code> Write logs to a custom path. <p>Because <code>nerd create</code> runs inside the CLI\u2019s task framework, you can also supply <code>--backend</code>, <code>--threads</code>, <code>--mem-gb</code>, etc., in the <code>run</code> section to scale the job.</p>"},{"location":"cli/create/#examples","title":"Examples","text":"<pre><code># Minimal inline config\nnerd create --config examples/create_minimal.yaml --db nerd.sqlite\n\n# Full CSV import (buffers, constructs, sequencing runs, samples)\nnerd create --config examples/create_all_samples/create_all.yaml --db nerd.sqlite\n\n# Separate probing sample import\nnerd create --config examples/create_all_samples/create_probing_samples.yaml \\\n            --db nerd.sqlite\n</code></pre> <p>Once metadata is ingested, you\u2019re ready to run <code>nmr_*</code> or <code>probe_timecourse</code> tasks on the same database.</p>"},{"location":"cli/mut_count/","title":"<code>nerd mut_count</code>","text":"<p><code>nerd mut_count</code> orchestrates mutation counting on sequencing samples (e.g., FASTQ files). It stages FASTQs, runs the configured plugin (default SHAPEMapper), and records per-nucleotide mutation rates into <code>probe_fmod_values</code>.</p> <pre><code>nerd mut_count --config PATH/TO/config.yaml --db PATH/TO/nerd.sqlite\n</code></pre> <p>Without <code>--db</code>, <code>&lt;run.output_dir&gt;/nerd.sqlite</code> is used.</p>"},{"location":"cli/mut_count/#configuration-layout","title":"Configuration Layout","text":"<pre><code>run:\n  label: mutcount_demo\n  output_dir: examples\n  backend: local\n  threads: 8\n\nmut_count:\n  plugin: shapemapper\n  params:\n    n_proc: 8\n  samples:\n    - sample_name: 001-EKC-fourU-37C-30s\n      fq_dir: /data/runs/2024-09-01\n      r1_file: sample_R1.fastq.gz\n      r2_file: sample_R2.fastq.gz\n      sequencing_run_name: 2024-09-01_SHAPE\n      construct: 4U_wt\n      buffer: pH6.5_A\n      reaction_group: 37_1\n      probe: dms\n      probe_concentration: 0.016\n      rt_protocol: SSIII\n      temperature: 37\n      replicate: 1\n      reaction_time: 30\n      treated: 2\n</code></pre> <p><code>mut_count.samples</code> can be inline (as above) or a CSV path. Each row must reference existing constructs, buffers, and sequencing runs, or NERD will resolve them via <code>create</code> imports.</p>"},{"location":"cli/mut_count/#key-fields","title":"Key Fields","text":"Field Description <code>plugin</code> Registered mutation-count plugin (e.g., <code>shapemapper</code>). <code>params</code> Plugin-specific options (e.g., <code>n_proc</code>, <code>amplicon</code>). <code>samples</code> List/CSV describing parent (and optional derived) samples to process. <code>dry_run</code> Skip plugin execution and only stage metadata (optional). <p>Derived samples can be specified through <code>derived_samples</code> when you need to subsample or filter hits before counting mutations.</p>"},{"location":"cli/mut_count/#workflow-summary","title":"Workflow Summary","text":"<ol> <li>Resolve sequencing runs, constructs, buffers, and builds FASTA targets.</li> <li>Stage FASTQs (locally or remotely) and run the plugin command.</li> <li>Parse the resulting mutation profiles and insert them into <code>probe_fmod_values</code>/<code>probe_fmod_runs</code>.</li> </ol> <p>Probing reactions (rg labels) are linked automatically if <code>reaction_group</code> is supplied.</p>"},{"location":"cli/mut_count/#outputs","title":"Outputs","text":"<ul> <li>Entries in <code>probe_fmod_runs</code> (run metadata, software version, arguments).</li> <li>Mutation rates in <code>probe_fmod_values</code> (per nt_id, reaction, valtype).</li> <li>Optional per-read histograms and staging artifacts under <code>&lt;output_dir&gt;/&lt;label&gt;/mut_count_latest/</code>.</li> </ul>"},{"location":"cli/mut_count/#examples","title":"Examples","text":"<pre><code># Run SHAPEMapper on all samples listed in CSV\nnerd mut_count --config examples/create_all_samples/create_samples.yaml --db nerd.sqlite\n\n# Dry run to inspect staging\nnerd mut_count --config configs/mutcount.yaml --db nerd.sqlite --dry-run\n</code></pre> <p>After <code>mut_count</code>, you can proceed to <code>probe_timecourse</code> or Arrhenius tasks using the inserted mutation rates.</p>"},{"location":"cli/nmr_add_kinetics/","title":"<code>nerd nmr_add_kinetics</code>","text":"<p><code>nerd nmr_add_kinetics</code> fits NMR-based adduction kinetics (k_add) for reactions registered via <code>nmr_create</code>. It relies on trace files (peak and DMS traces) staged in the database and records results in <code>nmr_fit_runs</code>/<code>nmr_fit_params</code>.</p> <pre><code>nerd nmr_add_kinetics --config PATH/TO/config.yaml --db PATH/TO/nerd.sqlite\n</code></pre> <p>If <code>--db</code> is omitted, the CLI uses <code>&lt;run.output_dir&gt;/nerd.sqlite</code>.</p>"},{"location":"cli/nmr_add_kinetics/#configuration-layout","title":"Configuration Layout","text":"<pre><code>run:\n  label: nmr_add_demo\n  output_dir: examples\n  backend: local\n\nnmr_add_kinetics:\n  search_roots:\n    - ../../test_data\n  plugin: ode_lsq_ntp_add\n  plugin_options:\n    k_add_init: 0.002\n    k_deg_init: 0.001\n  fit_params:\n    S_factor: 1.0\n  species:\n    - ATP_C8\n</code></pre>"},{"location":"cli/nmr_add_kinetics/#key-fields","title":"Key Fields","text":"Field Description <code>search_roots</code> Directories to resolve trace files if <code>trace_files.path</code> is relative. <code>plugin</code> Registered NMR fit engine (defaults to <code>ode_lsq_ntp_add</code>). <code>plugin_options</code> Passed to the engine constructor (e.g., initial guesses). <code>fit_params</code> Forwarded to the plugin\u2019s <code>fit</code> call (e.g., scaling factors). <code>species</code> One or more trace species to fit (e.g., <code>ATP_C8</code>). If omitted, defaults to <code>substrate</code> or <code>ntp_probe</code>. <p>Optional filters:</p> <ul> <li><code>reaction_ids</code>: explicit list of reactions to fit.</li> <li><code>substrates</code>: restrict to specific substrates (e.g., <code>ATP</code>, <code>CTP</code>).</li> <li><code>buffer</code>, <code>construct</code>, <code>temperature</code>, etc., can be enforced via custom pre-filters (deprecated in favor of species/substrate lists).</li> </ul>"},{"location":"cli/nmr_add_kinetics/#prerequisites","title":"Prerequisites","text":"<ol> <li>Run <code>nerd nmr_create</code> with <code>trace_files</code> entries:    <code>yaml    trace_files:      peak_trace:        path: nmr_ntp_adduction_data/ATP_peak_percentages/20_1_peak8.csv        species: ATP_C8      dms_trace:        path: nmr_ntp_adduction_data/ATP_peak_percentages/20_1_peakDMS.csv        species: ATP_DMS</code></li> <li>Ensure constructs, buffers, and sequencing runs are already in the database (<code>nerd create</code>).</li> </ol>"},{"location":"cli/nmr_add_kinetics/#outputs","title":"Outputs","text":"<ul> <li>New rows in <code>nmr_fit_runs</code> capturing plugin name, model, species, and run metadata.</li> <li>Associated parameters in <code>nmr_fit_params</code> (<code>k_value</code>, <code>k_error</code>, <code>r2</code>, <code>chisq</code>, plus plugin diagnostics).</li> <li>JSON artifacts under <code>&lt;output_dir&gt;/&lt;label&gt;/nmr_add_kinetics_latest/results/</code> describing each reaction fit.</li> </ul>"},{"location":"cli/nmr_add_kinetics/#examples","title":"Examples","text":"<pre><code># Fit ATP C8 adduction kinetics\nnerd nmr_add_kinetics --config examples/nmr_fit_add/configs/fit_add.yaml                       --db examples/nerd.sqlite\n\n# Run with multiple species (C8 + DMS)\nnerd nmr_add_kinetics --config configs/fit_add_multi.yaml --db nerd.sqlite\n</code></pre> <p>After the fits complete, downstream tasks (e.g., <code>tempgrad_fit</code> with <code>data_source: nmr</code>) can consume the stored rates for Arrhenius analysis.</p>"},{"location":"cli/nmr_create/","title":"<code>nerd nmr_create</code>","text":"<p><code>nerd nmr_create</code> registers NMR reactions and their trace files in the database, enabling downstream kinetics tasks (<code>nmr_deg_kinetics</code>, <code>nmr_add_kinetics</code>). You can inline reactions in YAML or point to CSV sheets.</p> <pre><code>nerd nmr_create --config PATH/TO/config.yaml --db PATH/TO/nerd.sqlite\n</code></pre> <p>If <code>--db</code> is omitted, <code>&lt;run.output_dir&gt;/nerd.sqlite</code> is used.</p>"},{"location":"cli/nmr_create/#configuration-layout","title":"Configuration Layout","text":"<pre><code>run:\n  label: nmr_create_deg\n  output_dir: examples\n\nnmr_create:\n  search_roots:\n    - ../../test_data\n  reactions:\n    - reaction_type: deg\n      temperature: 25\n      replicate: 1\n      probe: dms\n      probe_conc: 0.01585\n      buffer: Schwalbe_bistris\n      substrate: none\n      substrate_conc: 0\n      num_scans: 64\n      time_per_read: 5\n      total_kinetic_reads: 96\n      total_kinetic_time: 28800\n      nmr_machine: A600\n      trace_files:\n        decay_trace: nmr_degradation_data/dms_schwalbe_25C_rep1.csv\n</code></pre>"},{"location":"cli/nmr_create/#key-fields","title":"Key Fields","text":"Field Description <code>search_roots</code> Extra directories to resolve trace file paths. <code>reactions</code> List (or CSV filename) describing each NMR reaction to ingest. <code>trace_files</code> Mapping of trace roles (e.g., <code>decay_trace</code>, <code>peak_trace</code>, <code>dms_trace</code>) to file paths. Can be <code>{path, species}</code> for adduction traces. <p>Optional: <code>kinetic_data_dir</code>, <code>mnova_analysis_dir</code>, <code>raw_fid_dir</code> for bookkeeping.</p>"},{"location":"cli/nmr_create/#csv-mode","title":"CSV Mode","text":"<p>If <code>reactions</code> is a string (e.g., <code>reactions: nmr_degradation_samples.csv</code>), NERD loads that CSV. Headers should match the YAML fields above. Use <code>search_roots</code> so relative trace paths resolve correctly.</p>"},{"location":"cli/nmr_create/#outputs","title":"Outputs","text":"<ul> <li>Rows in <code>nmr_reactions</code> (temperature, replicate, buffer, construct association).</li> <li>Trace metadata in <code>nmr_trace_files</code> for each role/path/species.</li> <li>Run artifacts and logs under <code>&lt;output_dir&gt;/&lt;label&gt;/nmr_create_latest/</code>.</li> </ul>"},{"location":"cli/nmr_create/#examples","title":"Examples","text":"<pre><code># Import degradation reactions from CSV\nnerd nmr_create --config examples/nmr_create/nmr_create_deg.yaml --db nerd.sqlite\n\n# Inline adduction entries\nnerd nmr_create --config configs/nmr_create_add.yaml --db nerd.sqlite\n</code></pre> <p>After <code>nmr_create</code>, run <code>nmr_deg_kinetics</code> or <code>nmr_add_kinetics</code> to fit the registered reactions.</p>"},{"location":"cli/nmr_deg_kinetics/","title":"<code>nerd nmr_deg_kinetics</code>","text":"<p><code>nerd nmr_deg_kinetics</code> fits first-order degradation rates (k_deg) for NMR reactions registered via <code>nmr_create</code>. Each reaction needs a <code>decay_trace</code> file recorded in the database trace list.</p> <pre><code>nerd nmr_deg_kinetics --config PATH/TO/config.yaml --db PATH/TO/nerd.sqlite\n</code></pre> <p>If <code>--db</code> is omitted, the CLI uses <code>&lt;run.output_dir&gt;/nerd.sqlite</code>.</p>"},{"location":"cli/nmr_deg_kinetics/#configuration-layout","title":"Configuration Layout","text":"<pre><code>run:\n  label: nmr_deg_demo\n  output_dir: examples\n  backend: local\n\nnmr_deg_kinetics:\n  search_roots:\n    - ../../test_data\n  plugin: lmfit_deg\n  plugin_options:\n    model: exponential\n  fit_params:\n    normalize: true\n  reaction_ids: [1, 2, 3]\n</code></pre>"},{"location":"cli/nmr_deg_kinetics/#key-fields","title":"Key Fields","text":"Field Description <code>search_roots</code> Directories to resolve trace paths when they are relative. <code>plugin</code> Registered degradation fit engine (<code>lmfit_deg</code> is the default). <code>plugin_options</code> Passed to the engine constructor (e.g., choose a different model). <code>fit_params</code> Forwarded to the plugin\u2019s <code>fit</code> call; allows run-specific overrides. <code>reaction_ids</code> Optional explicit reactions to fit. Leave empty to fit every degradation reaction in the database."},{"location":"cli/nmr_deg_kinetics/#prerequisites","title":"Prerequisites","text":"<ol> <li>Ingest reactions via <code>nerd nmr_create</code>, including trace mappings:    <code>yaml    trace_files:      decay_trace: nmr_degradation_data/dms_schwalbe_25C_rep1.csv</code></li> <li>Ensure constructs, buffers, and sequencing runs exist in the database (<code>nerd create</code>).</li> </ol>"},{"location":"cli/nmr_deg_kinetics/#outputs","title":"Outputs","text":"<ul> <li>Rows in <code>nmr_fit_runs</code> with plugin, model, and reaction metadata.</li> <li>Associated <code>nmr_fit_params</code> capturing <code>k_value</code>, <code>k_error</code>, <code>r2</code>, <code>chisq</code>, etc.</li> <li>JSON summaries under <code>&lt;output_dir&gt;/&lt;label&gt;/nmr_deg_kinetics_latest/results/</code>.</li> </ul>"},{"location":"cli/nmr_deg_kinetics/#examples","title":"Examples","text":"<pre><code># Fit all degradation reactions\nnerd nmr_deg_kinetics --config examples/nmr_fit_deg/configs/fit_deg.yaml                        --db examples/nerd.sqlite\n\n# Fit a subset of reaction IDs\nnerd nmr_deg_kinetics --config configs/fit_deg_subset.yaml --db nerd.sqlite\n</code></pre> <p>Once the fits are recorded, Arrhenius analysis can reuse them via <code>tempgrad_fit</code> with <code>data_source: nmr</code>.</p>"},{"location":"cli/probe_timecourse/","title":"<code>nerd probe_timecourse</code>","text":"<p><code>nerd probe_timecourse</code> fits chemical probing time-course data stored in <code>probe_fmod_values</code>, producing per-nucleotide parameters (free fits, global deg fits, constrained refits). Results are written to <code>probe_tc_fit_runs</code>/<code>probe_tc_fit_params</code> and JSON artifacts for each reaction group.</p> <pre><code>nerd probe_timecourse --config PATH/TO/config.yaml --db PATH/TO/nerd.sqlite\n</code></pre> <p>Omitting <code>--db</code> defaults to <code>&lt;run.output_dir&gt;/nerd.sqlite</code>.</p>"},{"location":"cli/probe_timecourse/#configuration-layout","title":"Configuration Layout","text":"<pre><code>run:\n  label: probe_tc_demo\n  output_dir: examples\n\nprobe_timecourse:\n  engine: python_baseline\n  rounds:\n    - round1_free\n    - round2_global\n    - round3_constrained\n  rg_ids: [101, 102]\n  valtype:\n    - modrate\n    - GAmodrate\n  min_points: 3\n  overwrite: true\n\n  engine_options:\n    global_selection: ac_only\n    global_filters:\n      r2_threshold: 0.75\n    initial_kdeg: 0.0025\n</code></pre>"},{"location":"cli/probe_timecourse/#key-fields","title":"Key Fields","text":"Field Description <code>engine</code> Registered timecourse engine (<code>python_baseline</code> is the default). <code>rounds</code> Subset of the three-stage workflow (free, global, constrained). <code>rg_ids</code> Reaction-group IDs to process; leave empty to process all. <code>valtype</code> Which value type(s) to use. Provide a string for one, or a list (e.g., <code>[modrate, GAmodrate]</code>) to aggregate multiple. <code>min_points</code> Minimum points required per nucleotide (default 3). <code>overwrite</code> When true, existing fits in <code>probe_tc_fit_runs</code> are replaced. <code>engine_options</code> Passed to the engine; e.g., global selection filters, initial guesses. <p>Additional filters: <code>nt_ids</code>, <code>species</code>, <code>buffer</code>, <code>construct</code>, <code>fit_kind</code>, etc. (ignored unless supported by the engine). See the example configs under <code>examples/probing_timecourse_fits/</code>.</p>"},{"location":"cli/probe_timecourse/#workflow-overview","title":"Workflow Overview","text":"<ol> <li>Round 1 (<code>round1_free</code>) \u2013 independent per-nucleotide fits (k_obs, k_deg, f_mod0).</li> <li>Round 2 (<code>round2_global</code>) \u2013 global k_deg using filtered nucleotides (A/C only, R\u00b2 threshold, etc.).</li> <li>Round 3 (<code>round3_constrained</code>) \u2013 refit each nucleotide with k_deg fixed from round 2.</li> </ol> <p>You can run any subset of rounds depending on the goal (e.g., skip global and only produce free fits by listing <code>round1_free</code>).</p>"},{"location":"cli/probe_timecourse/#outputs","title":"Outputs","text":"<ul> <li>Per-nucleotide parameters and diagnostics in <code>probe_tc_fit_params</code> (tall format).</li> <li>Run-level metadata in <code>probe_tc_fit_runs</code> (fit kind, rg_id, nt_id, timestamp).</li> <li>JSON summaries under <code>&lt;output_dir&gt;/&lt;label&gt;/probe_timecourse_latest/results/</code>.</li> </ul>"},{"location":"cli/probe_timecourse/#examples","title":"Examples","text":"<pre><code># Full three-round fit for selected reaction groups\nnerd probe_timecourse --config examples/probing_timecourse_fits/config.yaml                       --db examples/nerd.sqlite\n\n# Only run free fits\nnerd probe_timecourse --config configs/probe_tc_free.yaml --db nerd.sqlite\n\n# Constrained refits using existing global kdeg\nnerd probe_timecourse --config configs/probe_tc_constrained.yaml --db nerd.sqlite\n</code></pre> <p>Once fits are completed, downstream tasks (e.g., <code>tempgrad_fit</code> with <code>data_source: probe_tc</code>) can reuse the stored kinetics for Arrhenius analysis.</p>"},{"location":"cli/tempgrad_fit/","title":"<code>nerd tempgrad_fit</code>","text":"<p><code>nerd tempgrad_fit</code> performs temperature-gradient analyses (Arrhenius or two-state melt) using the pluggable engines under <code>pipeline/plugins/tempgrad</code>. It can consume NMR fits (<code>data_source: nmr</code>) or probe timecourse fits (<code>data_source: probe_tc</code>) and stores results in <code>tempgrad_fit_runs</code>/<code>tempgrad_fit_params</code>.</p> <pre><code>nerd tempgrad_fit --config PATH/TO/config.yaml --db PATH/TO/nerd.sqlite\n</code></pre> <p>If <code>--db</code> is omitted, NERD falls back to <code>&lt;run.output_dir&gt;/nerd.sqlite</code>.</p>"},{"location":"cli/tempgrad_fit/#configuration-layout","title":"Configuration Layout","text":"<pre><code>run:\n  label: tempgrad_demo\n  output_dir: examples\n\ntempgrad_fit:\n  mode: arrhenius                 # or two_state_melt\n  data_source: probe_tc           # nmr or probe_tc\n  overwrite: true\n\n  filters:\n    construct: 4U_wt\n    base: A\n    melt_threshold_c: 60\n    fit_kind: round3_constrained\n\n  engine_options:\n    temperature_unit: c\n    weighted: true\n</code></pre>"},{"location":"cli/tempgrad_fit/#key-fields","title":"Key Fields","text":"Field Description <code>mode</code> Selects the engine (<code>arrhenius</code>, <code>two_state_melt</code>). <code>data_source</code> <code>nmr</code> (uses <code>nmr_fit_runs</code>) or <code>probe_tc</code> (uses <code>probe_tc_fit_params</code>). <code>filters</code> Constraints on construct, buffer, base, nt, melt threshold, etc. <code>engine_options</code> Passed to the engine; e.g., <code>weighted</code>, <code>temperature_unit</code>, <code>melt_threshold_c</code>. <code>overwrite</code> Removes existing rows in <code>tempgrad_fit_runs/tempgrad_fit_params</code> before inserting new ones. <p>For <code>probe_tc</code>, grouping happens automatically: reactions are grouped by construct, buffer, probe, concentration, and RT protocol; temperatures are filtered using <code>melt_threshold_c</code> before fitting each nucleotide.</p>"},{"location":"cli/tempgrad_fit/#supported-data-sources","title":"Supported Data Sources","text":"<ol> <li> <p>NMR Arrhenius (<code>data_source: nmr</code>)    Pulls completed fits from <code>nmr_fit_runs</code>, using <code>k_value</code>/<code>k_error</code> to produce log-linear fits.</p> </li> <li> <p>Probe Arrhenius (<code>data_source: probe_tc</code>)    Aggregates <code>probe_tc</code> fits on the fly. You can filter by constructs, buffers, bases, reaction-group IDs, etc. Weighted regression uses <code>log_kobs_err</code> when available.</p> </li> <li> <p>Two-state melt (<code>mode: two_state_melt</code>)    A placeholder stub exists; hook in your custom engine or supply <code>series</code> overrides until implemented.</p> </li> </ol>"},{"location":"cli/tempgrad_fit/#outputs","title":"Outputs","text":"<ul> <li>A run record per series in <code>tempgrad_fit_runs</code> (fit kind, scope, data source, metadata).</li> <li>Tall-format parameters and diagnostics in <code>tempgrad_fit_params</code>.</li> <li>JSON artifacts under <code>&lt;output_dir&gt;/&lt;label&gt;/tempgrad_fit_latest/results/tempgrad_result.json</code>.</li> </ul>"},{"location":"cli/tempgrad_fit/#examples","title":"Examples","text":"<pre><code># NMR degradation Arrhenius (species: dms)\nnerd tempgrad_fit --config manuscript_pipeline/03_nmr_arrhenius/tempgrad_deg.yaml \\\n                  --db manuscript_pipeline/nerd.sqlite\n\n# Probe Arrhenius, melted-only ATP nucleotides\nnerd tempgrad_fit --config examples/probe_tempgrad_arrhenius/config.yaml \\\n                  --db examples/nerd.sqlite\n\n# Manual series override\nnerd tempgrad_fit --config configs/tempgrad_manual.yaml --db nerd.sqlite\n</code></pre> <p>After running <code>tempgrad_fit</code>, downstream notebooks or reports can summarize activation energies, global slope/intercept, and melt diagnostics directly from the tall-format tables.</p>"},{"location":"guides/nmr-kinetics/","title":"NMR Kinetics","text":"<p>NERD supports two complementary NMR kinetic experiments that measure probe chemistry independent of sequencing:</p> <ul> <li>Probe + water/buffer (degradation) \u2013 quantifies how fast the probe hydrolyzes or self-reacts in the assay buffer.</li> <li>Probe + nucleotide (adduction) \u2013 quantifies formation of probe\u2013NTP adducts that compete with probing.</li> </ul> <p>Both assays monitor the integral of known chemical-shift peaks (for example, DMS at ~4 ppm, NTP C8 around 8 ppm). CSV traces capture peak integrals as a function of time, and the CLI converts those traces into rate constants that feed downstream models.</p>"},{"location":"guides/nmr-kinetics/#data-prep-registration","title":"Data Prep &amp; Registration","text":"<p>Use <code>nerd run nmr_create</code> to register:</p> <ul> <li>The NMR reaction metadata (reaction type, substrate, buffer, concentrations).</li> <li>Trace files for each role:</li> <li><code>decay_trace</code> for degradation.</li> <li><code>peak_trace</code> (NTP reporter) and <code>dms_trace</code> for adduction.</li> </ul> <p>Each trace is a CSV with at least:</p> <pre><code>time,peak_integral\n0,0.98\n10,0.91\n...\n</code></pre> <p>For adduction, the column header is <code>peak</code> (representing normalized integral). Multiple traces must share the same time points; the task will intersect the times if one trace has additional rows.</p>"},{"location":"guides/nmr-kinetics/#degradation-fits-nmr_deg_kinetics","title":"Degradation Fits (<code>nmr_deg_kinetics</code>)","text":"<p>Degradation experiments expose probe to buffer (no nucleotide). The measured peak integral decays exponentially as reactive probe is consumed. Internally, the default <code>lmfit_deg</code> plugin fits:</p> <p>[ I(t) = A \\, e^{-t / \\tau} ]</p> <p>where:</p> <ul> <li>(I(t)) is the integrated peak height (e.g., DMS).</li> <li>(A) is the initial amplitude.</li> <li>(\\tau) is the decay time constant.</li> </ul> <p>The first-order degradation rate is reported as:</p> <p>[ k_{\\text{deg}} = \\frac{1}{\\tau} ]</p>"},{"location":"guides/nmr-kinetics/#configuration-example","title":"Configuration Example","text":"<pre><code>run:\n  label: water_deg\n  output_dir: outputs\n\nnmr_deg_kinetics:\n  reaction_ids: [12]        # IDs from nmr_create\n  plugin: lmfit_deg\n  species: dms              # Optional override; defaults to reaction probe\n</code></pre>"},{"location":"guides/nmr-kinetics/#outputs","title":"Outputs","text":"<ul> <li>A JSON artifact under <code>outputs/&lt;label&gt;/nmr_deg_kinetics/.../results</code>.</li> <li>Database rows in <code>nmr_fit_runs</code> (<code>plugin = lmfit_deg</code>) and <code>nmr_fit_params</code> (parameters such as <code>k_value</code>, <code>tau</code>, <code>chisq</code>).</li> </ul>"},{"location":"guides/nmr-kinetics/#adduction-fits-nmr_add_kinetics","title":"Adduction Fits (<code>nmr_add_kinetics</code>)","text":"<p>Adduction experiments mix probe with a nucleotide triphosphate (NTP). Two peaks are tracked:</p> <ol> <li>NTP C8 \u2013 decreases as adduct forms.</li> <li>DMS (probe) \u2013 decreases via both adduction and degradation pathways.</li> </ol> <p>The model treats the system with three state variables:</p> <ul> <li>(U(t)): unreacted NTP (scaled from the C8 peak).</li> <li>(S(t)): free probe (scaled from the DMS peak).</li> <li>(M(t)): adduct product (derived from the complement to (U)).</li> </ul> <p>The underlying ODEs (see <code>ode_lsq_ntp_add</code> plugin) are:</p> <p>[ \\begin{aligned} \\frac{dU}{dt} &amp;= -k_{\\text{add}} \\, U \\, S \\ \\frac{dS}{dt} &amp;= -k_{\\text{add}} \\, U \\, S - k_{\\text{deg}} \\, S \\ \\frac{dM}{dt} &amp;= k_{\\text{add}} \\, U \\, S \\end{aligned} ]</p> <p>Initial conditions use the registered concentrations:</p> <ul> <li>(U(0) = \\text{ntp_conc})</li> <li>(S(0) = \\text{dms_conc}) (defaults to 15.64 mM unless supplied)</li> <li>(M(0) = 0)</li> </ul> <p>A scaling factor (<code>S_factor</code>) can rescale the DMS trace before fitting. The solver (<code>scipy.integrate.solve_ivp</code>) integrates the system, and the optimizer (lmfit) adjusts (k_{\\text{add}}) (and optionally (k_{\\text{deg}})) to minimize residuals between simulated and observed curves.</p>"},{"location":"guides/nmr-kinetics/#configuration-example_1","title":"Configuration Example","text":"<pre><code>run:\n  label: ntp_adduct\n  output_dir: outputs\n\nnmr_add_kinetics:\n  reaction_ids: [21]\n  plugin: ode_lsq_ntp_add\n  plugin_options:\n    k_add_init: 0.003     # Optional initial guesses\n    k_deg_init: 0.001\n  trace_roles:\n    peak_trace: peak_trace\n    dms_trace: dms_trace\n</code></pre>"},{"location":"guides/nmr-kinetics/#outputs_1","title":"Outputs","text":"<ul> <li>JSON artifact summarizing fitted trajectories and parameters.</li> <li>Database rows in <code>nmr_fit_runs</code> (<code>plugin = ode_lsq_ntp_add</code>) and <code>nmr_fit_params</code> (entries for <code>k_value</code> \u2190 (k_{\\text{add}}), <code>k_deg</code>, R\u00b2, etc.).</li> <li>Diagnostics such as solver status and scaling factors stored in <code>nmr_fit_params</code> as text or numeric columns.</li> </ul>"},{"location":"guides/nmr-kinetics/#interpreting-results","title":"Interpreting Results","text":"<ol> <li>Inspect the JSON artifact for fitted curves and metadata (species labels, concentrations).</li> <li>Query the database:</li> <li><code>SELECT * FROM nmr_fit_runs WHERE plugin='lmfit_deg'</code> for degradation runs.</li> <li><code>SELECT * FROM nmr_fit_params WHERE param_name='k_value'</code> to compare rate constants across experiments.</li> <li>Cross-reference reaction metadata in <code>nmr_reactions</code> to verify buffer, substrate, and concentration settings.</li> </ol> <p>Combine these NMR-derived rates with probe time-course fits or temperature-gradient analyses to understand how probe chemistry, adduct formation, and reaction conditions interact across the full pipeline. The CLI keeps every step reproducible\u2014from raw integrals to stored rate constants\u2014so you can iterate on models without losing track of provenance.</p>"},{"location":"guides/probe-mutcount/","title":"Probe Mutational Counting","text":"<p>Time\u2011course kinetics and temperature\u2011gradient fits rely on accurate per\u2011nucleotide reactivities. NERD\u2019s <code>mut_count</code> task quantifies chemical modifications on RNA. Today this is predominantly achieved through reverse\u2011transcription\u2013based readouts (RT\u2011stop or RT\u2011MaP), where chemical adducts cause truncations or mutations during cDNA synthesis. NERD orchestrates external tools (e.g., ShapeMapper) to convert raw sequencing reads into modification rates, and is designed to extend to direct RNA detection approaches (e.g., Nanopore) in the future.</p>"},{"location":"guides/probe-mutcount/#from-fastq-to-reactivity","title":"From FASTQ to Reactivity","text":"<ol> <li>Start with parent sequencing samples registered via <code>nerd run create</code>. Each sample knows where its paired FASTQs live and which reaction group it belongs to.</li> <li>Optionally define derived samples (e.g., subsampled reads or single-hit filters) in the same config. The CLI will materialize these derivatives before counting.</li> <li>Run mutational counting with ShapeMapper through:</li> </ol> <p><code>bash    nerd run mut_count path/to/mutcount.yaml</code></p> <p>The config specifies which samples to process, ShapeMapper arguments, and staging options.</p> <p>NERD does not compute reactivities itself; instead, it coordinates established software packages to ensure reproducible and metadata\u2011tracked modification quantification.</p>"},{"location":"guides/probe-mutcount/#rt-stop-vs-rt-map","title":"RT-Stop vs RT-MaP","text":"<p>Two broad RT\u2011based strategies exist for detecting RNA chemical modifications:</p> <ul> <li>RT-stop: quantify cDNA truncations (not yet implemented in NERD).</li> <li>RT-MaP (Mutation Profiling): quantify mismatches and deletions introduced during reverse transcription. NERD currently supports this via ShapeMapper, enabling reactivity calculation for each nucleotide.</li> <li>Direct RNA detection (e.g., Nanopore): future support for base\u2011calling/modified\u2011base detection engines will enable modification calling directly from RNA reads without reverse transcription.</li> </ul> <p>This abstraction allows NERD to remain engine\u2011agnostic\u2014swap external tools or add new detection backends without rewriting pipelines.</p>"},{"location":"guides/probe-mutcount/#deployment-options","title":"Deployment Options","text":"<p>Mutational counting jobs can run:</p> <ul> <li>Locally (default): stage FASTQs into a temporary working directory and execute ShapeMapper on the same machine.</li> <li>HPC (SLURM): leverage the shared task runner to dispatch jobs to a SLURM cluster. Configure submission scripts in the <code>run</code> block or runner settings.</li> </ul> <p>Regardless of execution backend, the CLI collects outputs, logs provenance, and imports results into SQLite.</p>"},{"location":"guides/probe-mutcount/#derived-samples","title":"Derived Samples","text":"<p>Derived samples help control read depth or enforce per-read quality constraints before counting:</p> <ul> <li>Subsampled: use <code>seqtk sample</code> under the hood to create downsampled FASTQs (<code>kind: subsample</code>).</li> <li>Single-hit filters: call ShapeMapper once to identify reads with \u22641 modification, then use <code>seqtk subseq</code> to retain only those reads (<code>kind: filter_singlehit</code>).</li> </ul> <p>Derived definitions live in the <code>derived_samples</code> section of the <code>create</code> config. Once defined, they can be referenced just like parent sample names in the <code>mut_count</code> config.</p>"},{"location":"guides/probe-mutcount/#configuration-skeleton","title":"Configuration Skeleton","text":"<pre><code>run:\n  label: mutcount_run\n  output_dir: outputs\n\nmut_count:\n  samples:\n    - fourU_WT_65c_rep1_tp1\n    - fourU_WT_65c_rep1_tp1__subsample-n10000-s42\n  engine: shapemapper\n  engine_options:\n    shapemapper_path: /opt/shapemapper/bin/ShapeMapper.py\n    threads: 8\n  stage:\n    include_traces: false\n  filters:\n    reaction_groups: [65_1]\n</code></pre> <p>Key fields:</p> <ul> <li><code>samples</code>: parent or derived sample names.</li> <li><code>engine</code>: currently <code>shapemapper</code>; future values can point to other RT-MaP implementations.</li> <li><code>engine_options</code>: forwarded to the runner (binary path, threads, etc.).</li> <li><code>stage</code>: optional staging tweaks (e.g., include or skip trace outputs).</li> <li><code>filters</code>: constrain by reaction group, sample metadata, or derived-sample attributes.</li> </ul>"},{"location":"guides/probe-mutcount/#database-storage","title":"Database Storage","text":"<p>Mutational counting results land in two tables documented in the sample-organization guide:</p>"},{"location":"guides/probe-mutcount/#probe_fmod_runs","title":"<code>probe_fmod_runs</code>","text":"Column Meaning <code>id</code> Primary key. <code>software_name</code>, <code>software_version</code> Engine metadata (ShapeMapper version). <code>output_dir</code> Directory where raw tool outputs were staged. <code>s_id</code> Foreign key to <code>sequencing_samples</code> (parent sample). <code>created_at</code> Timestamp for the run. <p>Each entry represents a single execution of the counting tool for a sample (parent or derived).</p>"},{"location":"guides/probe-mutcount/#probe_fmod_values","title":"<code>probe_fmod_values</code>","text":"Column Meaning <code>nt_id</code> Foreign key to <code>meta_nucleotides</code> (construct + position). <code>fmod_run_id</code> Links back to <code>probe_fmod_runs</code>. <code>rxn_id</code> Optional foreign key to <code>probe_reactions</code> (for cross-referencing reaction conditions). <code>valtype</code> Type of value stored (<code>modrate</code>, <code>fmod</code>, etc.). <code>fmod_val</code> Reactivity or modification metric. <code>read_depth</code> Effective depth for that nucleotide. <code>outlier</code> Boolean flag for outlier handling."},{"location":"guides/probe-mutcount/#example-query","title":"Example Query","text":"<pre><code>SELECT\n  m.construct_id,\n  m.site,\n  v.fmod_val,\n  v.read_depth,\n  v.outlier\nFROM probe_fmod_values v\nJOIN meta_nucleotides m ON m.id = v.nt_id\nJOIN probe_fmod_runs r ON r.id = v.fmod_run_id\nWHERE r.software_name = 'ShapeMapper'\n  AND v.valtype = 'modrate'\n  AND r.s_id = (\n    SELECT id FROM sequencing_samples WHERE sample_name = 'fourU_WT_65c_rep1_tp1'\n  );\n</code></pre> <p>This query pulls the per-nucleotide <code>modrate</code> series for a given sample, alongside read depth and outlier flags.</p>"},{"location":"guides/probe-mutcount/#best-practices","title":"Best Practices","text":"<ul> <li>Keep FASTQs organized under the run-label directory (<code>outputs/&lt;label&gt;/fastqs</code>) for faster staging.</li> <li>Validate derived sample definitions\u2014ensure parent sample names match those inserted by the <code>create</code> task.</li> <li>Monitor log files in <code>outputs/&lt;label&gt;/run_logs</code> for ShapeMapper warnings or read filtering summaries.</li> <li>Re-run selectively by filtering on reaction groups or sample subsets to avoid redundant processing.</li> <li>Version bump: include ShapeMapper version in configs so <code>probe_fmod_runs</code> records remain traceable.</li> </ul> <p>Once mutation rates are in SQLite, you can pivot directly into probe timecourse fitting, temperature gradients, or custom analysis notebooks, confident that raw reads, derived samples, and reactivities are linked by shared identifiers.</p>"},{"location":"guides/probe-timecourse/","title":"Probe Timecourse Fitting","text":"<p>Time-course probing captures RNA reactivity at multiple reaction times (e.g., 15 s, 30 s, \u2026). Each time point is a quenched sample whose reactivity (<code>fmod</code>, <code>modrate</code>, or related metrics) is tracked per nucleotide. NERD\u2019s timecourse engine converts those trajectories into kinetic parameters that summarize how quickly each nucleotide reacts.</p> <ul> <li>Inputs: per-nucleotide reactivity values across time points (often <code>modrate</code> from mutational counting).</li> <li>Outputs: <code>k_obs</code> (composite rate), <code>k_deg</code>, and baseline offsets (<code>fmod0</code>) stored in the SQLite database and JSON artifacts.</li> </ul> <p>A separate guide covers how reactivity values are computed; this page focuses on the fitting workflow.</p>"},{"location":"guides/probe-timecourse/#kinetic-model","title":"Kinetic Model","text":"<p>Every nucleotide is fit to the standardized equation:</p> <p>[ r(t) = 1 - \\exp!\\left[-\\frac{k_{\\text{obs}}}{k_{\\text{deg}}} \\left(1 - e^{-k_{\\text{deg}} t}\\right)\\right] + r_0 ]</p> <p>where:</p> <ul> <li>(r(t)) is the observed reactivity at time (t).</li> <li>(k_{\\text{obs}}) is the composite rate (\\left(\\frac{K}{K+1} \\cdot \\frac{k_{\\text{add}} [P]0}{k{\\text{deg}}}\\right)).</li> <li>(k_{\\text{deg}}) is the degradation rate of the probe (shared across nucleotides within a molecule).</li> <li>(r_0) (<code>fmod0</code> in code) is a baseline offset capturing background signal.</li> </ul> <p>The free round fits all three parameters per nucleotide; subsequent rounds constrain (k_{\\text{deg}}) to enforce consistency.</p>"},{"location":"guides/probe-timecourse/#three-round-workflow","title":"Three-Round Workflow","text":"Round Purpose Key Details Round 1 \u2013 Free Fit each nucleotide independently. Provides initial estimates of (k_{\\text{obs}}), (k_{\\text{deg}}), (r_0); caches results for reuse. Round 2 \u2013 Global Share (k_{\\text{deg}}) across the molecule. Combines the best free fits (default R\u00b2 cutoff \u2248 0.8) and performs a global nonlinear regression. Round 3 \u2013 Constrained Refit all nucleotides with (k_{\\text{deg}}) fixed. Produces the final parameter set used downstream. <p>Why so many rounds?</p> <ol> <li>Stability: Free fits bootstrap good starting points and flag problematic traces.</li> <li>Physical consistency: Within the same molecule and condition, degradation should be common. The global round enforces that intuition.</li> <li>Final reporting: Constrained fits yield a clean, per-nucleotide parameter set with a shared (k_{\\text{deg}}).</li> </ol> <p>You can request one or more rounds in the config (<code>rounds: [round1_free, round3_constrained]</code>), but the full sequence is most common.</p>"},{"location":"guides/probe-timecourse/#engines-extensibility","title":"Engines &amp; Extensibility","text":"<p>NERD ships with a Python baseline engine (<code>python_baseline</code>) that uses <code>lmfit</code>. Other engines are available or planned:</p> <ul> <li><code>r_integration</code> (experimental): delegates fitting to R/NLME.</li> <li>Custom engines: register new backends by extending the <code>TimecourseEngine</code> interface.</li> </ul> <p>Each engine plugs into the same CLI interface, so swapping is as simple as changing <code>engine: r_integration</code> in the config.</p>"},{"location":"guides/probe-timecourse/#configuration-example","title":"Configuration Example","text":"<pre><code>run:\n  label: tc_fit_4U\n  output_dir: outputs\n\nprobe_timecourse:\n  engine: python_baseline\n  rounds: [round1_free, round2_global, round3_constrained]\n  rg_ids: [42]             # Reaction group IDs from `create`\n  valtype: modrate         # or fmod, etc.\n  min_points: 3            # Require at least three time points\n  engine_options:\n    r2_threshold: 0.8      # Minimum R\u00b2 to include in global round\n</code></pre> <p>Key fields:</p> <ul> <li><code>rg_ids</code>: which reaction groups to fit.</li> <li><code>valtype</code>: the reactivity metric to use. Defaults to <code>modrate</code>.</li> <li><code>engine_options.r2_threshold</code>: filter for global fits (Tuning this is important for challenging data).</li> <li><code>rounds</code>: any subset of <code>round1_free</code>, <code>round2_global</code>, <code>round3_constrained</code>.</li> </ul> <p>The task reads per-nucleotide time series from the database (loaded by <code>mut_count</code> and <code>create</code> tasks) and submits them to the engine.</p>"},{"location":"guides/probe-timecourse/#outputs-interpretation","title":"Outputs &amp; Interpretation","text":"<p>Each round generates:</p> <ul> <li><code>nucleotides/&lt;round&gt;/...</code> entries in the JSON artifact with parameters and diagnostics.</li> <li>Database inserts into <code>probe_tc_fit_runs</code> (one row per round + nucleotide set) and <code>probe_tc_fit_params</code> (per-parameter rows for <code>kobs</code>, <code>kdeg</code>, <code>fmod0</code>, errors, QC metrics).</li> </ul> <p>To inspect results:</p> <ol> <li>Open the JSON artifact under <code>outputs/&lt;label&gt;/probe_timecourse/.../results</code>.</li> <li>Query SQLite:    <code>sql    SELECT rg_id, nt_id, param_name, param_numeric    FROM probe_tc_fit_params    WHERE param_name IN ('kobs', 'kdeg')      AND fit_run_id IN (        SELECT id FROM probe_tc_fit_runs        WHERE fit_kind = 'round3_constrained'      );</code></li> <li>Join with <code>meta_nucleotides</code> or <code>probe_reactions</code> to annotate constructs, positions, or conditions.</li> </ol> <p>Remember: the headline metric is one (k_{\\text{obs}}) per nucleotide per reaction group. These composite rates feed directly into downstream analyses such as temperature-gradient fits or global kinetic comparisons.</p>"},{"location":"guides/probe-timecourse/#best-practices","title":"Best Practices","text":"<ul> <li>Use derived samples (subsampling, filtering) to generate cleaner mutational profiles before fitting.</li> <li>Inspect free-fit diagnostics (<code>r2</code>, <code>chisq</code>) to spot nucleotides with noisy or non-monotonic traces.</li> <li>Provide prior knowledge when available:</li> <li>Seed <code>log_kdeg_initial</code> in the config if degradation rates are known.</li> <li>Restrict <code>nt_ids</code> or <code>valtype</code> to focus on specific bases.</li> <li>Consider running alternate engines (Python vs R) to validate difficult datasets.</li> </ul> <p>With a consistent modeling approach, time-course fits become a reliable bridge from raw reactivities to interpretable kinetic fingerprints of your RNA construct.</p>"},{"location":"guides/sample-organization/","title":"Sample Organization &amp; Database Layout","text":"<p>NERD persists every piece of metadata, analysis configuration, and fit result inside a single SQLite database (<code>nerd.sqlite</code>). A lightweight relational store gives us a few big wins:</p> <ul> <li>Transactions keep inserts and updates consistent, even when multiple CLI tasks run in sequence.</li> <li>Foreign keys model the lab reality\u2014constructs, buffers, reaction groups, and fit runs link explicitly.</li> <li>The file is portable: copy <code>nerd.sqlite</code> alongside figures and configs to reproduce an analysis.</li> </ul> <p>Think of the database as the canonical record of an experiment. CSVs define starting metadata, FASTQs supply raw reads, fits generate parameters, but the SQLite file ties everything together.</p>"},{"location":"guides/sample-organization/#schema-at-a-glance","title":"Schema at a Glance","text":"<p>Tables are grouped by function:</p> <ul> <li>core_* \u2013 task orchestration (<code>core_tasks</code>, <code>core_task_members</code>).</li> <li>meta_* \u2013 reusable metadata (constructs, buffers, nucleotides).</li> <li>sample creation \u2013 sequencing runs, samples, reaction groups, and probe reactions.</li> <li>probe_fmod* \u2013 outputs from mutational counting pipelines (ShapeMapper, etc.).</li> <li>probe_tc* \u2013 free/global/constrained time-course fit runs and parameters.</li> <li>nmr_* \u2013 NMR reaction definitions, trace files, and kinetics fits.</li> <li>tempgrad_* \u2013 Arrhenius and melt fits derived from probe or NMR data.</li> </ul> <p>The sections below sketch how each area fits together so you can quickly orient in the database browser of your choice.</p>"},{"location":"guides/sample-organization/#core-task-tables","title":"Core Task Tables","text":"Table Purpose <code>core_tasks</code> One row per CLI task execution (e.g., <code>create</code>, <code>mut_count</code>). Stores status, config hash, timestamps. <code>core_task_members</code> Links a task to specific entities (sample IDs, reaction groups) to capture scope. <code>core_cached_tasks</code> Records when a task reuses prior results via the caching mechanism. <p>These tables are the audit trail. If the CLI reports that a run completed, you\u2019ll see a matching row with <code>state='completed'</code>. Failures, reruns, and cached executions are all tracked here.</p>"},{"location":"guides/sample-organization/#metadata-meta_","title":"Metadata (<code>meta_\u2026</code>)","text":"Table Key Columns Notes <code>meta_constructs</code> <code>disp_name</code>, <code>family</code>, <code>version</code> Unique construct definitions. <code>meta_nucleotides</code> <code>construct_id</code>, <code>site</code>, <code>base</code> Per-nucleotide metadata; generated if not provided. <code>meta_buffers</code> <code>name</code>, <code>pH</code>, <code>composition</code> Buffer recipes referenced by reactions. <p>Constructs and buffers are shared resources. When you import new samples, the CLI resolves construct/display names back into these tables. Deleting a construct cascades to its nucleotides thanks to foreign keys.</p>"},{"location":"guides/sample-organization/#sample-creation-organization","title":"Sample Creation &amp; Organization","text":"Table Purpose <code>sequencing_runs</code> One row per instrument run (MiSeq, NovaSeq, etc.). <code>sequencing_samples</code> Parent samples pointing to FASTQ directories/files. <code>sequencing_derived_samples</code> Virtual samples produced by subsampling/filtering operations. <code>probe_reaction_groups</code> Labels that group related probe reactions (e.g., time course replicates). <code>probe_reactions</code> Connects a sequencing sample to constructs, buffers, probe chemistry, and reaction conditions. <p>Typical flow: <code>create</code> inserts sequencing runs and samples, <code>probe_reaction_groups</code> tracks the lab-defined grouping (e.g., <code>65_1</code>), and <code>probe_reactions</code> attaches experimental context (temperature, probe concentration). Derived samples record how a <code>mut_count</code> task generated filtered FASTQs; parent-child relationships let downstream tasks trace provenance.</p> <p>Foreign-key highlights:</p> <ul> <li><code>probe_reactions.s_id \u2192 sequencing_samples.id</code></li> <li><code>probe_reactions.construct_id \u2192 meta_constructs.id</code></li> <li><code>probe_reactions.buffer_id \u2192 meta_buffers.id</code></li> </ul>"},{"location":"guides/sample-organization/#mutational-counting-probe_fmod_","title":"Mutational Counting (<code>probe_fmod_*</code>)","text":"Table Purpose <code>probe_fmod_runs</code> Each invocation of a mutational counting tool for a sample. <code>probe_fmod_values</code> Per-nucleotide reactivity (e.g., <code>modrate</code>) plus depth and QC flags. <p>When you run <code>nerd run mut_count</code>, the task registers a <code>probe_fmod_runs</code> row, inserts per-nucleotide values, and marks outliers. <code>probe_fmod_values.nt_id</code> points back to <code>meta_nucleotides</code>, so all reactivity data stays linked to constructs.</p>"},{"location":"guides/sample-organization/#probe-time-course-fits-probe_tc_","title":"Probe Time-Course Fits (<code>probe_tc_*</code>)","text":"Table Purpose <code>probe_tc_fit_runs</code> Catalog of free/global/constrained fits. Captures round type, reaction group, valtype, and optional fmod run linkage. <code>probe_tc_fit_params</code> Tall table storing fit parameters, errors, or QC metrics keyed by <code>fit_run_id</code>. <p>Each time-course task can spawn multiple rounds; the CLI writes one <code>probe_tc_fit_runs</code> row per round or scope. Parameters (e.g., <code>log_kobs</code>, <code>log_kdeg</code>) are stored as rows in <code>probe_tc_fit_params</code>, making it easy to extend with new metrics.</p>"},{"location":"guides/sample-organization/#nmr-experiments-nmr_","title":"NMR Experiments (<code>nmr_*</code>)","text":"Table Purpose <code>nmr_reactions</code> Experiment definition (reaction type, substrate, buffer, replicate info). <code>nmr_trace_files</code> File registry per reaction and role (decay trace, peak trace, DMS trace). <code>nmr_fit_runs</code> Each kinetic model execution, including plugin name and status. <code>nmr_fit_params</code> Tall parameter storage for kinetics outputs (<code>k_value</code>, <code>k_error</code>, R\u00b2, etc.). <p>The workflow:</p> <ol> <li><code>nmr_create</code> registers trace files and reaction metadata.</li> <li><code>nmr_deg_kinetics</code> / <code>nmr_add_kinetics</code> draw inputs, stage trace files into a run directory, and execute the named plugin.</li> <li>Results land in <code>nmr_fit_runs</code> (one row per reaction fit) with parameters normalized into <code>nmr_fit_params</code>.</li> </ol>"},{"location":"guides/sample-organization/#temperature-gradient-fits-tempgrad_","title":"Temperature-Gradient Fits (<code>tempgrad_*</code>)","text":"Table Purpose <code>tempgrad_fit_runs</code> Top-level record for each Arrhenius or two-state fit execution. <code>tempgrad_series</code> Series metadata (construct, buffer, probe) for individual fit curves. <code>tempgrad_series_params</code> Parameters per series (activation energy, slopes, intercepts). <code>tempgrad_series_diagnostics</code> Diagnostics like R\u00b2, RMSE, weight usage. <p>Arrhenius runs use per-series regression; two-state fits may share baselines and store additional free energy estimates. Every series references the reaction group or source data so you can trace the input pipeline.</p>"},{"location":"guides/sample-organization/#navigating-the-database","title":"Navigating the Database","text":"<p>Open <code>nerd.sqlite</code> in your favorite viewer (DB Browser for SQLite, Datasette, TablePlus). A few orientation tips:</p> <ul> <li>Start with <code>core_tasks</code> to see what ran. Use <code>task_id</code> to jump to downstream artifacts (<code>nmr_fit_runs.task_id</code>, provenance logs under the run directory).</li> <li>Follow foreign keys. Most tables use integer IDs with descriptive columns (<code>rg_label</code>, <code>sample_name</code>) for human readability.</li> <li>Tall parameter tables (<code>*_fit_params</code>) include both numeric and text columns. Filter by <code>param_name</code> to extract specific values.</li> <li>JSON artifacts. Tasks also dump companion JSON files in <code>run/output_dir/&lt;label&gt;/&lt;task&gt;/create___cfg-.../results</code>. The SQLite entries are designed to point back to those files via paths stored in metadata tables.</li> </ul> <p>With this structure your analyses are reproducible: rerunning a task updates entries, derived tables stay in sync, and every parameter ties back to the sample and construct that produced it. Use the CLI to orchestrate; use the database to audit, explore, and share.</p>"},{"location":"guides/tempgrad-fit/","title":"Temperature Gradient Fits","text":"<p>Coming soon: Arrhenius and melt models from NMR and probe data.</p>"}]}